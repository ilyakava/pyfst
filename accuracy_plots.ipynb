{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plots accuracy figures.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch0/ilya/locDoc/miniconda2/envs/venvtf/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from hsi_data import multiversion_matfile_get_field, dset_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npz_results_from_dirs(res_files):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      res_files: list<str>: list of full paths to results.npz files\n",
    "    Returns:\n",
    "      dir_results: dict< str, float >: maps mask name to accuracy\n",
    "    \"\"\"\n",
    "    dir_results = {}\n",
    "    for npz_name in res_files:\n",
    "        results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "        k = results.keys()[0]\n",
    "        for k, v in results.iteritems():\n",
    "            if k in dir_results:\n",
    "                dir_results[k] = max(dir_results[k], v)\n",
    "            else:\n",
    "                dir_results[k] = v\n",
    "    return dir_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumulate\n",
    "def results_hash_to_mean_std(dir_results, samples=[10,20,50,90], zfill_amount=2):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      dir_results: dict< str, float >: maps mask name to accuracy\n",
    "    \"\"\"\n",
    "    dir_y = []\n",
    "    dir_y_std = []\n",
    "    #samples = [5,10,20,50]\n",
    "    for samp in samples:\n",
    "        if samp < 1:\n",
    "            samp = int(samp * 10000)\n",
    "            as_str = '_p%s_' % str(samp).zfill(zfill_amount)\n",
    "        else:\n",
    "            as_str = '_s%s_' % str(samp).zfill(zfill_amount)\n",
    "        valids = [(k,v) for (k,v) in dir_results.iteritems() if as_str in k]\n",
    "        values_ = np.array([v for (k,v) in valids])\n",
    "        # make sure values are an array of numbers\n",
    "        values = []\n",
    "        for v in values_:\n",
    "            if not type(v) in [float, np.float, np.float64] and len(v):\n",
    "                values.append(v[0])\n",
    "            else:\n",
    "                values.append(v)\n",
    "        values = np.array(values)\n",
    "        \n",
    "        dir_y.append(values.mean())\n",
    "        dir_y_std.append(values.std())\n",
    "    return np.array(dir_y), np.array(dir_y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zfill_amount = 2\n",
    "samples = [10,20,50,90] # PU SSS\n",
    "# samples = [5,10,20,50] # KSC SSS\n",
    "samples = [3,5,10,20] # Dist\n",
    "# samples = [0.0200,0.0500,0.1000]\n",
    "samples = [0.005,0.0100,0.0200] # PU hi data\n",
    "zfill_amount = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paviaU distributed\n",
    "# samples\n",
    "samples = [5,10,20] # Dist\n",
    "zfill_amount = 2\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/paviau_dist_fst/SVM_results_1983226215.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "fst_means, fst_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# dffn\n",
    "model_type_dir = '/scratch0/ilya/locDoc/pyfst/models/dffn'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'PaviaU_distributed_trainval_s*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "dffn_means, dffn_stds = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# eap\n",
    "model_type_dir = '/scratch0/ilya/locDoc/pyfst/models/eap'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'PaviaU_distributed_trainval_s*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "eap_means, eap_stds = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# raw\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/models/pu_raw_svm/SVM_results_6410196752.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "raw_means, raw_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# tang\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/models/pu_tang_svm/SVM_results_1051942010.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "tang_means, tang_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# gabor\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/paviau_dist_gabor/SVM_results_5650820553.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "gabor_means, gabor_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "\n",
    "# percentages\n",
    "samples = [0.005,0.0100,0.0200] # PU hi data\n",
    "zfill_amount = 4\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/paviau_dist_fst/SVM_results_1983226215.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "fst_means2, fst_stds2 = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# dffn\n",
    "model_type_dir = '/scratch0/ilya/locDoc/pyfst/models/dffn'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'PaviaU_distributed_trainval_p*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "dffn_means2, dffn_stds2 = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# eap\n",
    "model_type_dir = '/scratch0/ilya/locDoc/pyfst/models/eap'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'PaviaU_distributed_trainval_p*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "eap_means2, eap_stds2 = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# raw\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/models/pu_raw_svm/SVM_results_6410196752.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "raw_means2, raw_stds2 = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# tang\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/models/pu_tang_svm/SVM_results_1051942010.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "tang_means2, tang_stds2 = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# gabor\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/paviau_dist_gabor/SVM_results_5650820553.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "gabor_means2, gabor_stds2 = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "\n",
    "\n",
    "# concat\n",
    "fst_means = np.concatenate([fst_means, fst_means2])\n",
    "fst_stds = np.concatenate([fst_stds, fst_stds2])\n",
    "\n",
    "dffn_means = np.concatenate([dffn_means, dffn_means2])\n",
    "dffn_stds = np.concatenate([dffn_stds, dffn_stds2])\n",
    "\n",
    "eap_means = np.concatenate([eap_means, eap_means2])\n",
    "eap_stds = np.concatenate([eap_stds, eap_stds2])\n",
    "\n",
    "raw_means = np.concatenate([raw_means, raw_means2])\n",
    "raw_stds = np.concatenate([raw_stds, raw_stds2])\n",
    "\n",
    "tang_means = np.concatenate([tang_means, tang_means2])\n",
    "tang_stds = np.concatenate([tang_stds, tang_stds2])\n",
    "\n",
    "gabor_means = np.concatenate([gabor_means, gabor_means2])\n",
    "gabor_stds = np.concatenate([gabor_stds, gabor_stds2])\n",
    "\n",
    "t = [s_ / (42776 / 9.0) for s_ in [5,10,20]] + [0.005,0.0100,0.0200]\n",
    "t = [100*s_ for s_ in t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58cdb41f4d4428aab541f962cbad9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[6.4, 4.8])\n",
    "\n",
    "plt.plot(t, fst_means, 'd-', color='b')\n",
    "plt.fill_between(t, fst_means-fst_stds, fst_means+fst_stds, facecolor='b', alpha=0.3)\n",
    "\n",
    "plt.plot(t, dffn_means, 'd-', color='y')\n",
    "plt.fill_between(t, dffn_means-dffn_stds, dffn_means+dffn_stds, facecolor='y', alpha=0.3)\n",
    "\n",
    "plt.plot(t, eap_means, 'd-', color='g')\n",
    "plt.fill_between(t, eap_means-eap_stds, eap_means+eap_stds, facecolor='g', alpha=0.3)\n",
    "\n",
    "plt.plot(t, raw_means, 'd-', color='purple')\n",
    "plt.fill_between(t, raw_means-raw_stds, raw_means+raw_stds, facecolor='purple', alpha=0.3)\n",
    "\n",
    "plt.plot(t, tang_means, 'd-', color='r')\n",
    "plt.fill_between(t, tang_means-tang_stds, tang_means+tang_stds, facecolor='r', alpha=0.3)\n",
    "\n",
    "plt.plot(t, gabor_means, 'd-', color='black')\n",
    "plt.fill_between(t, gabor_means-gabor_stds, gabor_means+gabor_stds, facecolor='black', alpha=0.3)\n",
    "\n",
    "plt.ylim(ymin=0, ymax=1)\n",
    "plt.legend(['3D FST', 'DFFN', 'EAP', 'Raw', '3D WST', '3D Gabor'], loc=\"lower right\")\n",
    "plt.xlabel('Percentage Of Training Data')\n",
    "plt.ylabel('Overall Accuracy')\n",
    "plt.title('PaviaU')\n",
    "\n",
    "plt.savefig('/scratch0/ilya/locDownloads/temp/tgrs_grids/PaviaU_perfs.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n"
     ]
    }
   ],
   "source": [
    "# IP distributed\n",
    "# samples\n",
    "samples = [5,10] # Dist\n",
    "zfill_amount = 2\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/ip_dist_fst/SVM_results_351309908.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "fst_means, fst_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# dffn\n",
    "model_type_dir = '/scratch0/ilya/locDoc/pyfst/models/dffn'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'IP_distributed_trainval_s*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "dffn_means, dffn_stds = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# eap\n",
    "model_type_dir = '/scratch0/ilya/locDoc/pyfst/models/eap'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'IP_distributed_trainval_s*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "eap_means, eap_stds = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# raw\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/models/ip_raw_svm/SVM_results_3322018531.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "raw_means, raw_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# tang\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/models/ip_tang_svm/SVM_results_4726895580.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "tang_means, tang_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# gabor\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/ip_dist_gabor/SVM_results_6565639639.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "gabor_means, gabor_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "\n",
    "# percentages\n",
    "samples = [0.0200,0.0500,0.1000]\n",
    "zfill_amount = 4\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/ip_dist_fst/SVM_results_351309908.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "fst_means2, fst_stds2 = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# dffn\n",
    "model_type_dir = '/scratch0/ilya/locDoc/pyfst/models/dffn'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'IP_distributed_trainval_p*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "dffn_means2, dffn_stds2 = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# eap\n",
    "model_type_dir = '/scratch0/ilya/locDoc/pyfst/models/eap'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'IP_distributed_trainval_p*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "eap_means2, eap_stds2 = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# raw\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/models/ip_raw_svm/SVM_results_3322018531.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "raw_means2, raw_stds2 = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# tang\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/models/ip_tang_svm/SVM_results_4726895580.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "tang_means2, tang_stds2 = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# gabor\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/ip_dist_gabor/SVM_results_6565639639.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "gabor_means2, gabor_stds2 = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "\n",
    "\n",
    "# concat\n",
    "fst_means = np.concatenate([fst_means, fst_means2])\n",
    "fst_stds = np.concatenate([fst_stds, fst_stds2])\n",
    "\n",
    "dffn_means = np.concatenate([dffn_means, dffn_means2])\n",
    "dffn_stds = np.concatenate([dffn_stds, dffn_stds2])\n",
    "\n",
    "eap_means = np.concatenate([eap_means, eap_means2])\n",
    "eap_stds = np.concatenate([eap_stds, eap_stds2])\n",
    "\n",
    "raw_means = np.concatenate([raw_means, raw_means2])\n",
    "raw_stds = np.concatenate([raw_stds, raw_stds2])\n",
    "\n",
    "tang_means = np.concatenate([tang_means, tang_means2])\n",
    "tang_stds = np.concatenate([tang_stds, tang_stds2])\n",
    "\n",
    "gabor_means = np.concatenate([gabor_means, gabor_means2])\n",
    "gabor_stds = np.concatenate([gabor_stds, gabor_stds2])\n",
    "\n",
    "t = [s_ / (10249 / 16.0) for s_ in [5,10]] + [0.0200,0.0500,0.1000]\n",
    "t = [100*s_ for s_ in t]\n",
    "# t = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cf03f1e9b945c0a7952efb26108eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(t, fst_means, 'd-', color='b')\n",
    "plt.fill_between(t, fst_means-fst_stds, fst_means+fst_stds, facecolor='b', alpha=0.3)\n",
    "\n",
    "plt.plot(t, dffn_means, 'd-', color='y')\n",
    "plt.fill_between(t, dffn_means-dffn_stds, dffn_means+dffn_stds, facecolor='y', alpha=0.3)\n",
    "\n",
    "plt.plot(t, eap_means, 'd-', color='g')\n",
    "plt.fill_between(t, eap_means-eap_stds, eap_means+eap_stds, facecolor='g', alpha=0.3)\n",
    "\n",
    "plt.plot(t, raw_means, 'd-', color='purple')\n",
    "plt.fill_between(t, raw_means-raw_stds, raw_means+raw_stds, facecolor='purple', alpha=0.3)\n",
    "\n",
    "plt.plot(t, tang_means, 'd-', color='r')\n",
    "plt.fill_between(t, tang_means-tang_stds, tang_means+tang_stds, facecolor='r', alpha=0.3)\n",
    "\n",
    "plt.plot(t, gabor_means, 'd-', color='black')\n",
    "plt.fill_between(t, gabor_means-gabor_stds, gabor_means+gabor_stds, facecolor='black', alpha=0.3)\n",
    "\n",
    "plt.ylim(ymin=0, ymax=1)\n",
    "plt.legend(['3D FST', 'DFFN', 'EAP', 'Raw', '3D WST', '3D Gabor'], loc=\"lower right\")\n",
    "plt.xlabel('Percentage Of Training Data')\n",
    "plt.ylabel('Overall Accuracy')\n",
    "plt.title('Indian Pines')\n",
    "\n",
    "plt.savefig('/scratch0/ilya/locDownloads/temp/tgrs_grids/IP_perfs.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.59869726, 0.63241964, 0.66661412, 0.72653581]),\n",
       " array([0.04976261, 0.0470072 , 0.05326331, 0.04151317]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npz_name = '/scratch0/ilya/locDoc/pyfst/june_models/ksc_sss_fst/SVM_results_3701156503.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n"
     ]
    }
   ],
   "source": [
    "# KSC SSS\n",
    "# samples\n",
    "samples = [5,10,20,50] # Dist\n",
    "zfill_amount = 2\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/ksc_sss_fst/SVM_results_6403281027.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "fst_means, fst_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# # dffn\n",
    "model_type_dir = '/scratch0/ilya/locDoc/pyfst/models/dffn'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'KSC_strictsinglesite_trainval_s*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "dffn_means, dffn_stds = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# # eap\n",
    "model_type_dir = '/scratch0/ilya/locDoc/pyfst/models/eap'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'KSC_strictsinglesite_trainval_s*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "eap_means, eap_stds = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# raw\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/models/KSC_raw_svm/SVM_results_8411790995.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "raw_means, raw_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# tang\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/models/KSC_tang_svm/SVM_results_4618754307.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "tang_means, tang_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# gabor\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/ksc_sss_gabor/SVM_results_4069317804.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "gabor_means, gabor_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "\n",
    "t = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples & 5 & 10 & 20 & 50 \\\\  \\hline\n",
      "FST & 62.74 ($\\pm$ 4.1) & 65.86 ($\\pm$ 4.0) & 71.44 ($\\pm$ 3.6) & 75.66 ($\\pm$ 1.9) \\\\  \\hline\n",
      "WST & 53.30 ($\\pm$ 5.5) & 59.44 ($\\pm$ 4.3) & 65.15 ($\\pm$ 4.9) & 68.60 ($\\pm$ 4.4) \\\\  \\hline\n",
      "DFFN & 56.27 ($\\pm$ 11.9) & 49.63 ($\\pm$ 13.7) & 59.07 ($\\pm$ 7.5) & 55.66 ($\\pm$ 8.0) \\\\  \\hline\n",
      "EAP & 56.64 ($\\pm$ 6.0) & 61.17 ($\\pm$ 5.7) & 64.29 ($\\pm$ 2.5) & 61.86 ($\\pm$ 4.5) \\\\  \\hline\n",
      "Raw & 62.79 ($\\pm$ 4.3) & 67.61 ($\\pm$ 4.1) & 71.58 ($\\pm$ 1.8) & 74.61 ($\\pm$ 2.8) \\\\  \\hline\n",
      "Gabor & 63.56 ($\\pm$ 5.5) & 65.97 ($\\pm$ 4.5) & 70.93 ($\\pm$ 5.0) & 72.68 ($\\pm$ 2.9) \\\\  \\hline\n"
     ]
    }
   ],
   "source": [
    "print(' & '.join(['Samples'] + [str(s) for s in samples]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['FST'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(fst_means, fst_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['WST'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(tang_means, tang_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['DFFN'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(dffn_means, dffn_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['EAP'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(eap_means, eap_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['Raw'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(raw_means, raw_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['Gabor'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(gabor_means, gabor_stds)]) + ' \\\\\\\\  \\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742eeef6fd6942b597b6334b842e6cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(t, fst_means, 'd-', color='b')\n",
    "plt.fill_between(t, fst_means-fst_stds, fst_means+fst_stds, facecolor='b', alpha=0.3)\n",
    "\n",
    "plt.plot(t, dffn_means, 'd-', color='y')\n",
    "plt.fill_between(t, dffn_means-dffn_stds, dffn_means+dffn_stds, facecolor='y', alpha=0.3)\n",
    "\n",
    "plt.plot(t, eap_means, 'd-', color='g')\n",
    "plt.fill_between(t, eap_means-eap_stds, eap_means+eap_stds, facecolor='g', alpha=0.3)\n",
    "\n",
    "plt.plot(t, raw_means, 'd-', color='purple')\n",
    "plt.fill_between(t, raw_means-raw_stds, raw_means+raw_stds, facecolor='purple', alpha=0.3)\n",
    "\n",
    "plt.plot(t, tang_means, 'd-', color='r')\n",
    "plt.fill_between(t, tang_means-tang_stds, tang_means+tang_stds, facecolor='r', alpha=0.3)\n",
    "\n",
    "plt.plot(t, gabor_means, 'd-', color='black')\n",
    "plt.fill_between(t, gabor_means-gabor_stds, gabor_means+gabor_stds, facecolor='black', alpha=0.3)\n",
    "\n",
    "plt.ylim(ymin=0, ymax=1)\n",
    "plt.legend(['3D FST', 'DFFN', 'EAP', 'Raw', '3D WST', '3D Gabor'], loc=\"lower right\")\n",
    "plt.xlabel('Site Size')\n",
    "plt.ylabel('Overall Accuracy')\n",
    "plt.title('KSC - Training from One Site')\n",
    "\n",
    "plt.savefig('/scratch0/ilya/locDownloads/temp/tgrs_grids/KSC_SSS_perfs.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n"
     ]
    }
   ],
   "source": [
    "# PaviaU SSS\n",
    "# samples\n",
    "samples = [10,20,50,90] # Dist\n",
    "zfill_amount = 2\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/paviau_sss_fst/SVM_results_880721418.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "fst_means, fst_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# # dffn\n",
    "model_type_dir = '/scratch0/ilya/locDoc/pyfst/models/dffn'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'PaviaU_strictsinglesite_trainval_s*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "dffn_means, dffn_stds = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# # eap\n",
    "model_type_dir = '/scratch0/ilya/locDoc/pyfst/models/eap'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'PaviaU_strictsinglesite_trainval_s*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "eap_means, eap_stds = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# raw\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/models/pu_raw_svm/SVM_results_4231370088.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "raw_means, raw_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# tang\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/models/pu_tang_svm/SVM_results_899180662.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "tang_means, tang_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# gabor\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/paviau_sss_gabor/SVM_results_3702449457.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "gabor_means, gabor_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "\n",
    "\n",
    "t = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples & 10 & 20 & 50 & 90 \\\\  \\hline\n",
      "FST & 55.59 ($\\pm$ 10.3) & 53.31 ($\\pm$ 9.6) & 56.35 ($\\pm$ 8.4) & 59.33 ($\\pm$ 7.4) \\\\  \\hline\n",
      "WST & 44.53 ($\\pm$ 8.7) & 48.01 ($\\pm$ 8.1) & 49.48 ($\\pm$ 8.5) & 51.59 ($\\pm$ 6.6) \\\\  \\hline\n",
      "DFFN & 43.36 ($\\pm$ 14.8) & 41.59 ($\\pm$ 16.2) & 49.31 ($\\pm$ 10.4) & 48.32 ($\\pm$ 6.4) \\\\  \\hline\n",
      "EAP & 49.29 ($\\pm$ 13.1) & 54.84 ($\\pm$ 9.9) & 57.31 ($\\pm$ 7.5) & 56.81 ($\\pm$ 8.7) \\\\  \\hline\n",
      "Raw & 50.74 ($\\pm$ 11.0) & 53.11 ($\\pm$ 8.9) & 55.21 ($\\pm$ 9.0) & 55.24 ($\\pm$ 7.3) \\\\  \\hline\n",
      "Gabor & 52.96 ($\\pm$ 10.2) & 53.33 ($\\pm$ 8.9) & 56.97 ($\\pm$ 9.2) & 60.00 ($\\pm$ 9.7) \\\\  \\hline\n"
     ]
    }
   ],
   "source": [
    "print(' & '.join(['Samples'] + [str(s) for s in samples]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['FST'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(fst_means, fst_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['WST'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(tang_means, tang_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['DFFN'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(dffn_means, dffn_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['EAP'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(eap_means, eap_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['Raw'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(raw_means, raw_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['Gabor'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(gabor_means, gabor_stds)]) + ' \\\\\\\\  \\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ee6dd2e3a64768adfcfb3ba1fcc15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(t, fst_means, 'd-', color='b')\n",
    "plt.fill_between(t, fst_means-fst_stds, fst_means+fst_stds, facecolor='b', alpha=0.3)\n",
    "\n",
    "plt.plot(t, dffn_means, 'd-', color='y')\n",
    "plt.fill_between(t, dffn_means-dffn_stds, dffn_means+dffn_stds, facecolor='y', alpha=0.3)\n",
    "\n",
    "plt.plot(t, eap_means, 'd-', color='g')\n",
    "plt.fill_between(t, eap_means-eap_stds, eap_means+eap_stds, facecolor='g', alpha=0.3)\n",
    "\n",
    "plt.plot(t, raw_means, 'd-', color='purple')\n",
    "plt.fill_between(t, raw_means-raw_stds, raw_means+raw_stds, facecolor='purple', alpha=0.3)\n",
    "\n",
    "plt.plot(t, tang_means, 'd-', color='r')\n",
    "plt.fill_between(t, tang_means-tang_stds, tang_means+tang_stds, facecolor='r', alpha=0.3)\n",
    "\n",
    "plt.plot(t, gabor_means, 'd-', color='black')\n",
    "plt.fill_between(t, gabor_means-gabor_stds, gabor_means+gabor_stds, facecolor='black', alpha=0.3)\n",
    "\n",
    "plt.ylim(ymin=0, ymax=1)\n",
    "plt.legend(['3D FST', 'DFFN', 'EAP', 'Raw', '3D WST', '3D Gabor'], loc=\"lower right\")\n",
    "plt.xlabel('Site Size')\n",
    "plt.ylabel('Overall Accuracy')\n",
    "plt.title('PaviaU - Training from One Site')\n",
    "\n",
    "plt.savefig('/scratch0/ilya/locDownloads/temp/tgrs_grids/PaviaU_SSS_perfs.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n"
     ]
    }
   ],
   "source": [
    "# Bots SSS\n",
    "# samples\n",
    "samples = [3,5,10,20] # Dist\n",
    "zfill_amount = 2\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/bots_sss_fst/SVM_results_3535561787.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "fst_means, fst_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# # dffn\n",
    "model_type_dir = '/scratch0/ilya/locDoc/pyfst/models/dffn'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'Botswana_strictsinglesite_trainval_s*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "dffn_means, dffn_stds = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# # eap\n",
    "model_type_dir = '/scratch0/ilya/locDoc/pyfst/models/eap'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'Botswana_strictsinglesite_trainval_s*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "eap_means, eap_stds = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# raw\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/models/Botswana_raw_svm/SVM_results_1947462706.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "raw_means, raw_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# tang\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/models/Botswana_tang_svm/SVM_results_9172113203.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "tang_means, tang_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# gabor\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/bots_sss_gabor/SVM_results_7690107823.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "gabor_means, gabor_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "\n",
    "t = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples & 3 & 5 & 10 & 20 \\\\  \\hline\n",
      "FST & 76.42 ($\\pm$ 6.8) & 77.56 ($\\pm$ 4.8) & 79.79 ($\\pm$ 4.1) & 85.80 ($\\pm$ 2.6) \\\\  \\hline\n",
      "WST & 52.46 ($\\pm$ 4.9) & 56.26 ($\\pm$ 4.0) & 60.40 ($\\pm$ 3.9) & 68.90 ($\\pm$ 6.1) \\\\  \\hline\n",
      "DFFN & 32.96 ($\\pm$ 12.0) & 38.34 ($\\pm$ 10.6) & 40.81 ($\\pm$ 11.1) & 38.92 ($\\pm$ 4.2) \\\\  \\hline\n",
      "EAP & 66.43 ($\\pm$ 13.1) & 72.12 ($\\pm$ 5.4) & 72.25 ($\\pm$ 5.8) & 74.68 ($\\pm$ 6.4) \\\\  \\hline\n",
      "Raw & 70.98 ($\\pm$ 4.0) & 69.52 ($\\pm$ 4.2) & 75.67 ($\\pm$ 2.6) & 80.71 ($\\pm$ 2.1) \\\\  \\hline\n",
      "Gabor & 75.17 ($\\pm$ 5.8) & 75.78 ($\\pm$ 3.9) & 79.11 ($\\pm$ 4.1) & 84.83 ($\\pm$ 2.6) \\\\  \\hline\n"
     ]
    }
   ],
   "source": [
    "print(' & '.join(['Samples'] + [str(s) for s in samples]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['FST'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(fst_means, fst_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['WST'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(tang_means, tang_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['DFFN'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(dffn_means, dffn_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['EAP'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(eap_means, eap_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['Raw'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(raw_means, raw_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['Gabor'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(gabor_means, gabor_stds)]) + ' \\\\\\\\  \\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabe98e5194a4dcb92ee81431662a852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(t, fst_means, 'd-', color='b')\n",
    "plt.fill_between(t, fst_means-fst_stds, fst_means+fst_stds, facecolor='b', alpha=0.3)\n",
    "\n",
    "plt.plot(t, dffn_means, 'd-', color='y')\n",
    "plt.fill_between(t, dffn_means-dffn_stds, dffn_means+dffn_stds, facecolor='y', alpha=0.3)\n",
    "\n",
    "plt.plot(t, eap_means, 'd-', color='g')\n",
    "plt.fill_between(t, eap_means-eap_stds, eap_means+eap_stds, facecolor='g', alpha=0.3)\n",
    "\n",
    "plt.plot(t, raw_means, 'd-', color='purple')\n",
    "plt.fill_between(t, raw_means-raw_stds, raw_means+raw_stds, facecolor='purple', alpha=0.3)\n",
    "\n",
    "plt.plot(t, tang_means, 'd-', color='r')\n",
    "plt.fill_between(t, tang_means-tang_stds, tang_means+tang_stds, facecolor='r', alpha=0.3)\n",
    "\n",
    "plt.plot(t, gabor_means, 'd-', color='black')\n",
    "plt.fill_between(t, gabor_means-gabor_stds, gabor_means+gabor_stds, facecolor='black', alpha=0.3)\n",
    "\n",
    "plt.ylim(ymin=0, ymax=1)\n",
    "plt.legend(['3D FST', 'DFFN', 'EAP', 'Raw', '3D WST', '3D Gabor'], loc=\"lower right\")\n",
    "plt.title('Botswana - Training from One Site')\n",
    "plt.ylabel('Overall Accuracy')\n",
    "plt.xlabel('Site Size')\n",
    "\n",
    "plt.savefig('/scratch0/ilya/locDownloads/temp/tgrs_grids/Botswana_SSS_perfs.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n"
     ]
    }
   ],
   "source": [
    "# IP SSS\n",
    "# samples\n",
    "samples = [5,10] # Dist\n",
    "zfill_amount = 2\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/ip_sss_fst/SVM_results_1620725352.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "fst_means, fst_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# dffn\n",
    "model_type_dir = '/scratch1/ilya/locDoc/pyfst/june_models/dffn/ip/dffn'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'IP_strictsinglesite_trainval_s*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "dffn_means, dffn_stds = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# # eap\n",
    "model_type_dir = '/scratch1/ilya/locDoc/pyfst/june_models/eap/ip/eap'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'IP_strictsinglesite_trainval_s*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "eap_means, eap_stds = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# raw\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/june_models/IP_raw_svm/SVM_results_2495889255.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "raw_means, raw_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# tang\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/IP_wst/SVM_results_4206824447.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "tang_means, tang_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# gabor\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/ip_sss_gabor/SVM_results_9445987777.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "gabor_means, gabor_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "\n",
    "# percentages\n",
    "samples = [0.0200,0.0500,0.1000]\n",
    "zfill_amount = 4\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/ip_sss_fst/SVM_results_1620725352.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "fst_means2, fst_stds2 = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# dffn\n",
    "model_type_dir = '/scratch1/ilya/locDoc/pyfst/june_models/dffn/ip/dffn'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'IP_strictsinglesite_trainval_p*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "dffn_means2, dffn_stds2 = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# # eap\n",
    "model_type_dir = '/scratch1/ilya/locDoc/pyfst/june_models/eap/ip/eap'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'IP_strictsinglesite_trainval_p*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "eap_means2, eap_stds2 = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# raw\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/june_models/IP_raw_svm/SVM_results_2495889255.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "raw_means2, raw_stds2 = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# tang\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/IP_wst/SVM_results_4206824447.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "tang_means2, tang_stds2 = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# gabor\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/ip_sss_gabor/SVM_results_9445987777.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "gabor_means2, gabor_stds2 = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "\n",
    "\n",
    "# concat\n",
    "fst_means = np.concatenate([fst_means, fst_means2])\n",
    "fst_stds = np.concatenate([fst_stds, fst_stds2])\n",
    "\n",
    "dffn_means = np.concatenate([dffn_means, dffn_means2])\n",
    "dffn_stds = np.concatenate([dffn_stds, dffn_stds2])\n",
    "\n",
    "eap_means = np.concatenate([eap_means, eap_means2])\n",
    "eap_stds = np.concatenate([eap_stds, eap_stds2])\n",
    "\n",
    "raw_means = np.concatenate([raw_means, raw_means2])\n",
    "raw_stds = np.concatenate([raw_stds, raw_stds2])\n",
    "\n",
    "tang_means = np.concatenate([tang_means, tang_means2])\n",
    "tang_stds = np.concatenate([tang_stds, tang_stds2])\n",
    "\n",
    "gabor_means = np.concatenate([gabor_means, gabor_means2])\n",
    "gabor_stds = np.concatenate([gabor_stds, gabor_stds2])\n",
    "\n",
    "t = [s_ / (10249 / 16.0) for s_ in [5,10]] + [0.0200,0.0500,0.1000]\n",
    "t = [100*s_ for s_ in t]\n",
    "# t = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cfe95327fd54b2ca7b2e63bd695f1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(t, fst_means, 'd-', color='b')\n",
    "plt.fill_between(t, fst_means-fst_stds, fst_means+fst_stds, facecolor='b', alpha=0.3)\n",
    "\n",
    "plt.plot(t, dffn_means, 'd-', color='y')\n",
    "plt.fill_between(t, dffn_means-dffn_stds, dffn_means+dffn_stds, facecolor='y', alpha=0.3)\n",
    "\n",
    "plt.plot(t, eap_means, 'd-', color='g')\n",
    "plt.fill_between(t, eap_means-eap_stds, eap_means+eap_stds, facecolor='g', alpha=0.3)\n",
    "\n",
    "plt.plot(t, raw_means, 'd-', color='purple')\n",
    "plt.fill_between(t, raw_means-raw_stds, raw_means+raw_stds, facecolor='purple', alpha=0.3)\n",
    "\n",
    "plt.plot(t, tang_means, 'd-', color='r')\n",
    "plt.fill_between(t, tang_means-tang_stds, tang_means+tang_stds, facecolor='r', alpha=0.3)\n",
    "\n",
    "plt.plot(t, gabor_means, 'd-', color='black')\n",
    "plt.fill_between(t, gabor_means-gabor_stds, gabor_means+gabor_stds, facecolor='black', alpha=0.3)\n",
    "\n",
    "plt.ylim(ymin=0, ymax=1)\n",
    "plt.legend(['3D FST', 'DFFN', 'EAP', 'Raw', '3D WST', '3D Gabor'], loc=\"lower right\")\n",
    "# plt.legend(['3D FST', 'EAP', 'Raw', '3D WST', '3D Gabor'], loc=\"lower right\")\n",
    "plt.xlabel('Site Size (as Percentage Of Training Data)')\n",
    "plt.ylabel('Overall Accuracy')\n",
    "plt.title('Indian Pines - Training from One Site')\n",
    "\n",
    "plt.savefig('/scratch0/ilya/locDownloads/temp/tgrs_grids/IP_SSS_perfs.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n"
     ]
    }
   ],
   "source": [
    "# KSC dist\n",
    "# samples\n",
    "samples = [5,10,20,50] # Dist\n",
    "zfill_amount = 2\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/ksc_dist_fst/SVM_results_3378641093.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "fst_means, fst_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# dffn\n",
    "model_type_dir = '/scratch1/ilya/locDoc/pyfst/june_models/dffn/dffn'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'KSC_distributed_trainval_s*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "dffn_means, dffn_stds = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# # eap\n",
    "model_type_dir = '/scratch1/ilya/locDoc/pyfst/june_models/eap/eap'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'KSC_distributed_trainval_s*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "eap_means, eap_stds = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# raw\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/june_models/KSC_raw_svm/SVM_results_354804614.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "raw_means, raw_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# tang\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/KSC_wst/SVM_results_1732515566.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "tang_means, tang_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# gabor\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/ksc_dist_gabor/SVM_results_2540158683.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "gabor_means, gabor_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "\n",
    "t = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples & 5 & 10 & 20 & 50 \\\\  \\hline\n",
      "FST & 86.40 ($\\pm$ 2.8) & 93.18 ($\\pm$ 1.5) & 97.69 ($\\pm$ 0.8) & 99.68 ($\\pm$ 0.1) \\\\  \\hline\n",
      "WST & 82.23 ($\\pm$ 2.9) & 90.06 ($\\pm$ 1.1) & 95.98 ($\\pm$ 1.3) & 99.16 ($\\pm$ 0.2) \\\\  \\hline\n",
      "DFFN & 76.51 ($\\pm$ 5.1) & 89.87 ($\\pm$ 3.0) & 95.94 ($\\pm$ 1.5) & 98.47 ($\\pm$ 1.0) \\\\  \\hline\n",
      "EAP & 64.17 ($\\pm$ 7.1) & 68.47 ($\\pm$ 5.0) & 74.91 ($\\pm$ 2.3) & 81.47 ($\\pm$ 2.7) \\\\  \\hline\n",
      "Raw & 78.25 ($\\pm$ 2.1) & 84.36 ($\\pm$ 1.8) & 88.97 ($\\pm$ 0.6) & 92.56 ($\\pm$ 0.6) \\\\  \\hline\n",
      "Gabor & 83.16 ($\\pm$ 2.2) & 89.92 ($\\pm$ 1.5) & 95.01 ($\\pm$ 0.8) & 98.73 ($\\pm$ 0.4) \\\\  \\hline\n"
     ]
    }
   ],
   "source": [
    "print(' & '.join(['Samples'] + [str(s) for s in samples]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['FST'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(fst_means, fst_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['WST'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(tang_means, tang_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['DFFN'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(dffn_means, dffn_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['EAP'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(eap_means, eap_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['Raw'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(raw_means, raw_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['Gabor'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(gabor_means, gabor_stds)]) + ' \\\\\\\\  \\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef31af4e6d4e4615b814050216230b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(t, fst_means, 'd-', color='b')\n",
    "plt.fill_between(t, fst_means-fst_stds, fst_means+fst_stds, facecolor='b', alpha=0.3)\n",
    "\n",
    "plt.plot(t, dffn_means, 'd-', color='y')\n",
    "plt.fill_between(t, dffn_means-dffn_stds, dffn_means+dffn_stds, facecolor='y', alpha=0.3)\n",
    "\n",
    "plt.plot(t, eap_means, 'd-', color='g')\n",
    "plt.fill_between(t, eap_means-eap_stds, eap_means+eap_stds, facecolor='g', alpha=0.3)\n",
    "\n",
    "plt.plot(t, raw_means, 'd-', color='purple')\n",
    "plt.fill_between(t, raw_means-raw_stds, raw_means+raw_stds, facecolor='purple', alpha=0.3)\n",
    "\n",
    "plt.plot(t, tang_means, 'd-', color='r')\n",
    "plt.fill_between(t, tang_means-tang_stds, tang_means+tang_stds, facecolor='r', alpha=0.3)\n",
    "\n",
    "plt.plot(t, gabor_means, 'd-', color='black')\n",
    "plt.fill_between(t, gabor_means-gabor_stds, gabor_means+gabor_stds, facecolor='black', alpha=0.3)\n",
    "\n",
    "plt.ylim(ymin=0, ymax=1.025)\n",
    "plt.legend(['3D FST', 'DFFN', 'EAP', 'Raw', '3D WST', '3D Gabor'], loc=\"lower right\")\n",
    "plt.xlabel('Number Of Training Samples')\n",
    "plt.ylabel('Overall Accuracy')\n",
    "plt.title('KSC')\n",
    "\n",
    "plt.savefig('/scratch0/ilya/locDownloads/temp/tgrs_grids/KSC_perfs.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n",
      "found tuple\n"
     ]
    }
   ],
   "source": [
    "# Bots dist\n",
    "# samples\n",
    "samples = [3,5,10,20] # Dist\n",
    "zfill_amount = 2\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/bots_dist_fst/SVM_results_5664262905.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "fst_means, fst_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# # dffn\n",
    "model_type_dir = '/scratch1/ilya/locDoc/pyfst/june_models/dffn/dffn'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'Botswana_distributed_trainval_s*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "dffn_means, dffn_stds = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# # eap\n",
    "model_type_dir = '/scratch0/ilya/locDoc/pyfst/june_models/eap'\n",
    "res_files = glob.glob(os.path.join(model_type_dir, 'Botswana_distributed_trainval_s*/*/results.npz'))\n",
    "dir_results = load_npz_results_from_dirs(res_files)\n",
    "eap_means, eap_stds = results_hash_to_mean_std(dir_results, samples=samples, zfill_amount=zfill_amount)\n",
    "# raw\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/june_models/Botswana_raw_svm/SVM_results_8584562831.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "raw_means, raw_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# tang\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/Botswana_wst/SVM_results_4549174811.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "tang_means, tang_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "# gabor\n",
    "npz_name = '/scratch1/ilya/locDoc/pyfst/june_models/bots_dist_gabor/SVM_results_3348049280.npz'\n",
    "results = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "gabor_means, gabor_stds = results_hash_to_mean_std(results, samples=samples, zfill_amount=zfill_amount)\n",
    "\n",
    "t = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples & 3 & 5 & 10 & 20 \\\\  \\hline\n",
      "FST & 89.12 ($\\pm$ 2.0) & 91.83 ($\\pm$ 1.9) & 96.68 ($\\pm$ 1.0) & 98.62 ($\\pm$ 0.6) \\\\  \\hline\n",
      "WST & 79.16 ($\\pm$ 3.0) & 87.50 ($\\pm$ 4.5) & 94.49 ($\\pm$ 1.1) & 97.06 ($\\pm$ 1.0) \\\\  \\hline\n",
      "DFFN & 68.27 ($\\pm$ 12.9) & 77.83 ($\\pm$ 8.1) & 87.47 ($\\pm$ 4.4) & 95.11 ($\\pm$ 1.2) \\\\  \\hline\n",
      "EAP & 57.09 ($\\pm$ 29.7) & 80.34 ($\\pm$ 7.4) & 87.23 ($\\pm$ 2.5) & 92.53 ($\\pm$ 3.2) \\\\  \\hline\n",
      "Raw & 77.53 ($\\pm$ 3.6) & 80.91 ($\\pm$ 2.0) & 85.10 ($\\pm$ 1.8) & 88.85 ($\\pm$ 0.7) \\\\  \\hline\n",
      "Gabor & 85.72 ($\\pm$ 1.7) & 90.25 ($\\pm$ 2.7) & 95.49 ($\\pm$ 1.1) & 97.58 ($\\pm$ 0.5) \\\\  \\hline\n"
     ]
    }
   ],
   "source": [
    "print(' & '.join(['Samples'] + [str(s) for s in samples]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['FST'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(fst_means, fst_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['WST'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(tang_means, tang_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['DFFN'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(dffn_means, dffn_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['EAP'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(eap_means, eap_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['Raw'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(raw_means, raw_stds)]) + ' \\\\\\\\  \\hline')\n",
    "print(' & '.join(['Gabor'] + ['%.2f ($\\pm$ %.1f)' % (100*m_, 100*s_) for (m_,s_) in zip(gabor_means, gabor_stds)]) + ' \\\\\\\\  \\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb7b2b5cd1b40b48bc26933c0fd6b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(t, fst_means, 'd-', color='b')\n",
    "plt.fill_between(t, fst_means-fst_stds, fst_means+fst_stds, facecolor='b', alpha=0.3)\n",
    "\n",
    "plt.plot(t, dffn_means, 'd-', color='y')\n",
    "plt.fill_between(t, dffn_means-dffn_stds, dffn_means+dffn_stds, facecolor='y', alpha=0.3)\n",
    "\n",
    "plt.plot(t, eap_means, 'd-', color='g')\n",
    "plt.fill_between(t, eap_means-eap_stds, eap_means+eap_stds, facecolor='g', alpha=0.3)\n",
    "\n",
    "plt.plot(t, raw_means, 'd-', color='purple')\n",
    "plt.fill_between(t, raw_means-raw_stds, raw_means+raw_stds, facecolor='purple', alpha=0.3)\n",
    "\n",
    "plt.plot(t, tang_means, 'd-', color='r')\n",
    "plt.fill_between(t, tang_means-tang_stds, tang_means+tang_stds, facecolor='r', alpha=0.3)\n",
    "\n",
    "plt.plot(t, gabor_means, 'd-', color='black')\n",
    "plt.fill_between(t, gabor_means-gabor_stds, gabor_means+gabor_stds, facecolor='black', alpha=0.3)\n",
    "\n",
    "plt.ylim(ymin=0, ymax=1.025)\n",
    "plt.legend(['3D FST', 'DFFN', 'EAP', 'Raw', '3D WST', '3D Gabor'], loc=\"lower right\")\n",
    "plt.title('Botswana')\n",
    "plt.ylabel('Overall Accuracy')\n",
    "plt.xlabel('Number Of Training Samples')\n",
    "\n",
    "plt.savefig('/scratch0/ilya/locDownloads/temp/tgrs_grids/Botswana_perfs.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [50] # Dist\n",
    "zfill_amount = 2\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/june_models/ksc_fst_svm/SVM_results_7105350443.npz'\n",
    "results_fst = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "# fst_means, fst_stds = results_hash_to_mean_std(results_fst, samples=samples, zfill_amount=zfill_amount)\n",
    "# raw\n",
    "npz_name = '/scratch0/ilya/locDoc/pyfst/june_models/ksc_sss_gabor_svm/SVM_results_6223977032.npz'\n",
    "results_raw = np.load(npz_name, allow_pickle=True)['results'].item()\n",
    "# raw_means, raw_stds = results_hash_to_mean_std(results_raw, samples=samples, zfill_amount=zfill_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7563 +/- 0.0317\n"
     ]
    }
   ],
   "source": [
    "names = [k for k, v in results_fst.items()]\n",
    "arr = np.array([v[0] for k, v in results_fst.items()])\n",
    "print('%.4f +/- %.4f' %(arr.mean(), arr.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cfarhomes/ilyak/ilyakavalerov@gmail.com/ramawks69/pyfst/masks/KSC_strictsinglesite_trainval_s50_9_307364.mat'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = np.argsort(arr)\n",
    "arr[idxs[0]]\n",
    "names[idxs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7174 +/- 0.0301\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([v[0] for v in results_raw.values()])\n",
    "print('%.4f +/- %.4f' %(arr.mean(), arr.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6, 3, 9, 2, 7, 1, 8, 5, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/cfarhomes/ilyak/ilyakavalerov@gmail.com/ramawks69/pyfst/masks/KSC_strictsinglesite_trainval_s50_0_665848.mat': (0.7465468099101075,\n",
       "  0.6905851227182196,\n",
       "  0.7161611560197501),\n",
       " '/cfarhomes/ilyak/ilyakavalerov@gmail.com/ramawks69/pyfst/masks/KSC_strictsinglesite_trainval_s50_1_783796.mat': (0.7513703135277352,\n",
       "  0.7108108484290642,\n",
       "  0.7234463563064221),\n",
       " '/cfarhomes/ilyak/ilyakavalerov@gmail.com/ramawks69/pyfst/masks/KSC_strictsinglesite_trainval_s50_2_455308.mat': (0.7114667836000877,\n",
       "  0.6833432341927398,\n",
       "  0.6787416844380036),\n",
       " '/cfarhomes/ilyak/ilyakavalerov@gmail.com/ramawks69/pyfst/masks/KSC_strictsinglesite_trainval_s50_3_643924.mat': (0.7702258276693708,\n",
       "  0.747084657742553,\n",
       "  0.7435674013463986),\n",
       " '/cfarhomes/ilyak/ilyakavalerov@gmail.com/ramawks69/pyfst/masks/KSC_strictsinglesite_trainval_s50_4_514244.mat': (0.7860118395088797,\n",
       "  0.767013651889459,\n",
       "  0.760804044402019),\n",
       " '/cfarhomes/ilyak/ilyakavalerov@gmail.com/ramawks69/pyfst/masks/KSC_strictsinglesite_trainval_s50_5_762052.mat': (0.7546590659942995,\n",
       "  0.729418897480659,\n",
       "  0.7265882842261848),\n",
       " '/cfarhomes/ilyak/ilyakavalerov@gmail.com/ramawks69/pyfst/masks/KSC_strictsinglesite_trainval_s50_6_668196.mat': (0.7364613023459767,\n",
       "  0.6874506988520369,\n",
       "  0.7052463551110436),\n",
       " '/cfarhomes/ilyak/ilyakavalerov@gmail.com/ramawks69/pyfst/masks/KSC_strictsinglesite_trainval_s50_7_990120.mat': (0.7829423372067529,\n",
       "  0.7065990060955619,\n",
       "  0.7566660600459649),\n",
       " '/cfarhomes/ilyak/ilyakavalerov@gmail.com/ramawks69/pyfst/masks/KSC_strictsinglesite_trainval_s50_8_191432.mat': (0.7279105459329095,\n",
       "  0.6606674957366655,\n",
       "  0.6945082796920257),\n",
       " '/cfarhomes/ilyak/ilyakavalerov@gmail.com/ramawks69/pyfst/masks/KSC_strictsinglesite_trainval_s50_9_307364.mat': (0.6937075202806402,\n",
       "  0.6448612350350988,\n",
       "  0.658037214953282)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
